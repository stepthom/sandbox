{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground for Word and Document Embedding Slides\n",
    "- Stephen W. Thomas\n",
    "- Used for MMA 865 and MMAI 891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flair\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'big', 'cat', 'large', 'run', 'park', 'dog'}\n",
      "       big  cat  large  run  park  dog\n",
      "big      0    1      0    2     0    1\n",
      "cat      1    0      1    2     1    1\n",
      "large    0    1      0    2     0    2\n",
      "run      2    2      2    0     3    2\n",
      "park     0    1      0    3     0    2\n",
      "dog      1    1      2    2     2    0\n",
      "       big  cat  large  run  park  dog\n",
      "cat      1    0      1    2     1    1\n",
      "dog      1    1      2    2     2    0\n",
      "large    0    1      0    2     0    2\n",
      "big      0    1      0    2     0    1\n",
      "run      2    2      2    0     3    2\n",
      "park     0    1      0    3     0    2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sentences = ['big dog run park',\n",
    "             'big cat run park',\n",
    "             'large dog run park',\n",
    "             'run large cat dog']\n",
    "\n",
    "vocab = set()\n",
    "for sent in sentences:\n",
    "    for w in sent.split():\n",
    "        vocab.add(w)\n",
    "print(vocab)\n",
    "\n",
    "df = pd.DataFrame(columns=vocab)\n",
    "df = df.reindex(vocab)\n",
    "df = df.fillna(0)\n",
    "\n",
    "for sent in sentences:\n",
    "    words = sent.split()\n",
    "    for i, w in enumerate(words):\n",
    "        low = max(0, i-2)\n",
    "        high = min(len(words)-1, i+2)\n",
    "        for j in range(low, high+1):\n",
    "            if i == j:\n",
    "                continue\n",
    "            w2 = words[j]\n",
    "            df.loc[w, w2] = df.loc[w, w2] + 1\n",
    "            \n",
    "print(df)\n",
    "print(df.loc[['cat', 'dog', 'large', 'big', 'run', 'park']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence: \"Steve love Berlin .\" - 4 Tokens]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "# make a sentence\n",
    "sentence = Sentence('Steve love Berlin .')\n",
    "\n",
    "# load the NER tagger\n",
    "# other models include \"chunk\", \"pos\", \"frame\"\n",
    "tagger = SequenceTagger.load('ner')\n",
    "\n",
    "# run NER over sentence\n",
    "tagger.predict(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"Steve love Berlin .\" - 4 Tokens\n",
      "The following NER tags are found:\n",
      "PER-span [1]: \"Steve\"\n",
      "LOC-span [3]: \"Berlin\"\n"
     ]
    }
   ],
   "source": [
    "print(sentence)\n",
    "print('The following NER tags are found:')\n",
    "\n",
    "# iterate over entities and print\n",
    "for entity in sentence.get_spans('ner'):\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Steve love Berlin .', 'labels': [], 'entities': [{'text': 'Steve', 'start_pos': 0, 'end_pos': 5, 'type': 'PER', 'confidence': 0.9994787573814392}, {'text': 'Berlin', 'start_pos': 11, 'end_pos': 17, 'type': 'LOC', 'confidence': 0.998204231262207}]}\n"
     ]
    }
   ],
   "source": [
    "print(sentence.to_dict(tag_type='ner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings\n",
    "\n",
    "# GloVe embedding\n",
    "glove_embedding = WordEmbeddings('glove')\n",
    "\n",
    "# FastText embeddings over Web crawls\n",
    "crawl_embedding = WordEmbeddings('en-crawl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence: \"The grass is green and red .\" - 7 Tokens]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 The\n",
      "tensor([-0.0382, -0.2449,  0.7281, -0.3996,  0.0832,  0.0440, -0.3914,  0.3344,\n",
      "        -0.5755,  0.0875,  0.2879, -0.0673,  0.3091, -0.2638, -0.1323, -0.2076,\n",
      "         0.3340, -0.3385, -0.3174, -0.4834,  0.1464, -0.3730,  0.3458,  0.0520,\n",
      "         0.4495, -0.4697,  0.0263, -0.5415, -0.1552, -0.1411, -0.0397,  0.2828,\n",
      "         0.1439,  0.2346, -0.3102,  0.0862,  0.2040,  0.5262,  0.1716, -0.0824,\n",
      "        -0.7179, -0.4153,  0.2033, -0.1276,  0.4137,  0.5519,  0.5791, -0.3348,\n",
      "        -0.3656, -0.5486, -0.0629,  0.2658,  0.3020,  0.9977, -0.8048, -3.0243,\n",
      "         0.0125, -0.3694,  2.2167,  0.7220, -0.2498,  0.9214,  0.0345,  0.4674,\n",
      "         1.1079, -0.1936, -0.0746,  0.2335, -0.0521, -0.2204,  0.0572, -0.1581,\n",
      "        -0.3080, -0.4162,  0.3797,  0.1501, -0.5321, -0.2055, -1.2526,  0.0716,\n",
      "         0.7056,  0.4974, -0.4206,  0.2615, -1.5380, -0.3022, -0.0734, -0.2831,\n",
      "         0.3710, -0.2522,  0.0162, -0.0171, -0.3898,  0.8742, -0.7257, -0.5106,\n",
      "        -0.5203, -0.1459,  0.8278,  0.2706])\n",
      "Token: 2 grass\n",
      "tensor([-0.8135,  0.9404, -0.2405, -0.1350,  0.0557,  0.3363,  0.0802, -0.1015,\n",
      "        -0.5478, -0.3537,  0.0734,  0.2587,  0.1987, -0.1433,  0.2507,  0.4281,\n",
      "         0.1950,  0.5346,  0.7424,  0.0578, -0.3178,  0.9436,  0.8145, -0.0824,\n",
      "         0.6166,  0.7284, -0.3262, -1.3641,  0.1232,  0.5373, -0.5123,  0.0246,\n",
      "         1.0822, -0.2296,  0.6039,  0.5541, -0.9610,  0.4803,  0.0022,  0.5591,\n",
      "        -0.1637, -0.8468,  0.0741, -0.6216,  0.0260, -0.5162, -0.0525, -0.1418,\n",
      "        -0.0161, -0.4972, -0.5534, -0.4037,  0.5096,  1.0276, -0.0840, -1.1179,\n",
      "         0.3226,  0.4928,  0.9488,  0.2040,  0.5388,  0.8397, -0.0689,  0.3136,\n",
      "         1.0450, -0.2267, -0.0896, -0.6427,  0.6443, -1.1001, -0.0096,  0.2668,\n",
      "        -0.3230, -0.6065,  0.0479, -0.1664,  0.8571,  0.2335,  0.2539,  1.2546,\n",
      "         0.5472, -0.1980, -0.7186,  0.2076, -0.2587, -0.3650,  0.0834,  0.6932,\n",
      "         0.1574,  1.0931,  0.0913, -1.3773, -0.2717,  0.7071,  0.1872, -0.3307,\n",
      "        -0.2836,  0.1030,  1.2228,  0.8374])\n",
      "Token: 3 is\n",
      "tensor([-0.5426,  0.4148,  1.0322, -0.4024,  0.4669,  0.2182, -0.0749,  0.4733,\n",
      "         0.0810, -0.2208, -0.1281, -0.1144,  0.5089,  0.1157,  0.0282, -0.3628,\n",
      "         0.4382,  0.0475,  0.2028,  0.4986, -0.1007,  0.1327,  0.1697,  0.1165,\n",
      "         0.3135,  0.2571,  0.0928, -0.5683, -0.5297, -0.0515, -0.6733,  0.9253,\n",
      "         0.2693,  0.2273,  0.6636,  0.2622,  0.1972,  0.2609,  0.1877, -0.3454,\n",
      "        -0.4263,  0.1398,  0.5634, -0.5691,  0.1240, -0.1289,  0.7248, -0.2610,\n",
      "        -0.2631, -0.4360,  0.0789, -0.8415,  0.5160,  1.3997, -0.7646, -3.1453,\n",
      "        -0.2920, -0.3125,  1.5129,  0.5243,  0.2146,  0.4245, -0.0884, -0.1780,\n",
      "         1.1876,  0.1058,  0.7657,  0.2191,  0.3582, -0.1164,  0.0933, -0.6248,\n",
      "        -0.2190,  0.2180,  0.7406, -0.4374,  0.1434,  0.1472, -1.1605, -0.0505,\n",
      "         0.1268, -0.0144, -0.9868, -0.0913, -1.2054, -0.1197,  0.0478, -0.5400,\n",
      "         0.5246, -0.7096, -0.3253, -0.1346, -0.4131,  0.3343, -0.0072,  0.3225,\n",
      "        -0.0442, -1.2969,  0.7622,  0.4635])\n",
      "Token: 4 green\n",
      "tensor([-6.7907e-01,  3.4908e-01, -2.3984e-01, -9.9652e-01,  7.3782e-01,\n",
      "        -6.5911e-04,  2.8010e-01,  1.7287e-02, -3.6063e-01,  3.6955e-02,\n",
      "        -4.0395e-01,  2.4092e-02,  2.8958e-01,  4.0497e-01,  6.9992e-01,\n",
      "         2.5269e-01,  8.0350e-01,  4.9370e-02,  1.5562e-01, -6.3286e-03,\n",
      "        -2.9414e-01,  1.4728e-01,  1.8977e-01, -5.1791e-01,  3.6986e-01,\n",
      "         7.4582e-01,  8.2689e-02, -7.2601e-01, -4.0939e-01, -9.7822e-02,\n",
      "        -1.4096e-01,  7.1121e-01,  6.1933e-01, -2.5014e-01,  4.2250e-01,\n",
      "         4.8458e-01, -5.1915e-01,  7.7125e-01,  3.6685e-01,  4.9652e-01,\n",
      "        -4.1298e-02, -1.4683e+00,  2.0038e-01,  1.8591e-01,  4.9860e-02,\n",
      "        -1.7523e-01, -3.5528e-01,  9.4153e-01, -1.1898e-01, -5.1903e-01,\n",
      "        -1.1887e-02, -3.9186e-01, -1.7479e-01,  9.3451e-01, -5.8931e-01,\n",
      "        -2.7701e+00,  3.4522e-01,  8.6533e-01,  1.0808e+00, -1.0291e-01,\n",
      "        -9.1220e-02,  5.5092e-01, -3.9473e-01,  5.3676e-01,  1.0383e+00,\n",
      "        -4.0658e-01,  2.4590e-01, -2.6797e-01, -2.6036e-01, -1.4151e-01,\n",
      "        -1.2022e-01,  1.6234e-01, -7.4320e-01, -6.4728e-01,  4.7133e-02,\n",
      "         5.1642e-01,  1.9898e-01,  2.3919e-01,  1.2550e-01,  2.2471e-01,\n",
      "         8.2613e-01,  7.8328e-02, -5.7020e-01,  2.3934e-02, -1.5410e-01,\n",
      "        -2.5739e-01,  4.1262e-01, -4.6967e-01,  8.7914e-01,  7.2629e-01,\n",
      "         5.3862e-02, -1.1575e+00, -4.7835e-01,  2.0139e-01, -1.0051e+00,\n",
      "         1.1515e-01, -9.6609e-01,  1.2960e-01,  1.8388e-01, -3.0383e-02])\n",
      "Token: 5 and\n",
      "tensor([-0.0720,  0.2313,  0.0237, -0.5064,  0.3392,  0.1959, -0.3294,  0.1836,\n",
      "        -0.1806,  0.2896,  0.2045, -0.5496,  0.2740,  0.5833,  0.2047, -0.4923,\n",
      "         0.1997, -0.0702, -0.8805,  0.2948,  0.1407, -0.1009,  0.9945,  0.3697,\n",
      "         0.4455,  0.2900, -0.1376, -0.5637, -0.0294, -0.4122, -0.2527,  0.6318,\n",
      "        -0.4477,  0.2436, -0.1081,  0.2516,  0.4697,  0.3755, -0.2361, -0.1413,\n",
      "        -0.4454, -0.6574, -0.0424, -0.2864, -0.2881,  0.0638,  0.2028, -0.5354,\n",
      "         0.4131, -0.5972, -0.3861,  0.1939, -0.1781,  1.6618, -0.0118, -2.3737,\n",
      "         0.0584, -0.2698,  1.2823,  0.8192, -0.2232,  0.7293, -0.0532,  0.4351,\n",
      "         0.8501, -0.4293,  0.9266,  0.3905,  1.0585, -0.2456, -0.1826, -0.5328,\n",
      "         0.0595, -0.6602,  0.1899,  0.2884, -0.2434,  0.5278, -0.6576, -0.1408,\n",
      "         1.0491,  0.5134, -0.2382,  0.6989, -1.4813, -0.2487, -0.1794, -0.0591,\n",
      "        -0.0806, -0.4878,  0.0145, -0.6259, -0.3237,  0.4186, -1.0807,  0.4674,\n",
      "        -0.4993, -0.7189,  0.8689,  0.1954])\n",
      "Token: 6 red\n",
      "tensor([-0.3002,  0.5015, -0.1275, -0.8164,  0.3361,  0.3221, -0.0474,  0.0371,\n",
      "        -0.6158, -0.2233, -0.3913, -0.3189,  0.8709,  0.7445,  0.2371,  0.3177,\n",
      "         0.6132, -0.4816,  0.5545, -0.4877, -0.1187,  0.1520, -0.4388,  0.0452,\n",
      "         0.6666,  0.6442, -0.2181, -0.2422,  0.1765, -0.7179,  0.4889,  0.2287,\n",
      "         0.0800,  0.1224,  0.1864,  0.2052, -0.3514,  0.8317,  0.8658,  0.3340,\n",
      "         0.4451, -0.9813, -0.1045, -0.1020,  0.6549,  0.1068, -0.0953,  0.5637,\n",
      "         0.0488, -0.1084,  0.1054,  0.0412, -0.2939,  1.0227, -0.8657, -2.5878,\n",
      "        -0.5008,  0.9758,  1.5560,  0.4521, -0.5428,  0.8199, -0.6083,  0.1992,\n",
      "         0.7497, -0.3914,  0.0605, -0.0569, -0.0121,  0.0621,  0.0706, -0.4798,\n",
      "        -0.8661, -0.5934,  0.5765,  0.9837, -0.0351,  0.4203, -0.4059,  0.3510,\n",
      "         0.8739, -0.0694, -0.6869,  0.1860, -0.3690, -0.0218, -0.1014, -0.0376,\n",
      "         0.5682,  0.7438, -0.2871, -1.0705, -0.5070, -0.1258, -0.9040, -0.2559,\n",
      "        -1.3706,  0.1731,  0.1293, -0.4852])\n",
      "Token: 7 .\n",
      "tensor([-0.3398,  0.2094,  0.4635, -0.6479, -0.3838,  0.0380,  0.1713,  0.1598,\n",
      "         0.4662, -0.0192,  0.4148, -0.3435,  0.2687,  0.0446,  0.4213, -0.4103,\n",
      "         0.1546,  0.0222, -0.6465,  0.2526,  0.0431, -0.1945,  0.4652,  0.4565,\n",
      "         0.6859,  0.0913,  0.2188, -0.7035,  0.1679, -0.3508, -0.1263,  0.6638,\n",
      "        -0.2582,  0.0365, -0.1361,  0.4025,  0.1429,  0.3813, -0.1228, -0.4589,\n",
      "        -0.2528, -0.3043, -0.1121, -0.2618, -0.2248, -0.4455,  0.2991, -0.8561,\n",
      "        -0.1450, -0.4909,  0.0083, -0.1749,  0.2752,  1.4401, -0.2124, -2.8435,\n",
      "        -0.2796, -0.4572,  1.6386,  0.7881, -0.5526,  0.6500,  0.0864,  0.3901,\n",
      "         1.0632, -0.3538,  0.4833,  0.3460,  0.8417,  0.0987, -0.2421, -0.2705,\n",
      "         0.0453, -0.4015,  0.1139,  0.0062,  0.0367,  0.0185, -1.0213, -0.2081,\n",
      "         0.6407, -0.0688, -0.5864,  0.3348, -1.1432, -0.1148, -0.2509, -0.4591,\n",
      "        -0.0968, -0.1795, -0.0634, -0.6741, -0.0689,  0.5360, -0.8777,  0.3180,\n",
      "        -0.3924, -0.2339,  0.4730, -0.0288])\n"
     ]
    }
   ],
   "source": [
    "# create sentence.\n",
    "sentence = Sentence('The grass is green and red .')\n",
    "\n",
    "# embed a sentence using glove.\n",
    "glove_embedding.embed(sentence)\n",
    "\n",
    "# now check out the embedded tokens.\n",
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence: \"queen\" - 1 Tokens]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[Sentence: \"cheese\" - 1 Tokens]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8436118066310883"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "s1 = Sentence('queen')\n",
    "s2 = Sentence('cheese')\n",
    "\n",
    "glove_embedding.embed(s1)\n",
    "glove_embedding.embed(s2)\n",
    "\n",
    "a = s1[0].embedding\n",
    "b = s2[0].embedding\n",
    "cosine(a, b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
